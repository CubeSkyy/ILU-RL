[ql_args]
# alpha   = 0.5 (a schedule is being used so this parameter makes no difference)
# epsilon = 0.1 (a schedule is being used so this parameter makes no difference)
gamma = 0.9
choice_type = eps-greedy
replay_buffer = True
replay_buffer_size = 500
replay_buffer_batch_size = 64
replay_buffer_warm_up = 200


[dqn_args]
# TODO: model
lr = 5e-4
gamma = 0.8
buffer_size = 20000
batch_size = 64
exp_initial_p = 1.0
exp_final_p = 0.02
exp_schedule_timesteps = 40000
learning_starts = 0
target_net_update_interval = 2000